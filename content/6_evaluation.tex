\chapter{Evaluation} \label{chapter:EVALUATION}

We evaluated the implementation in terms of functionality and practicability.
For the evaluation, we used the setup described in the following section.


\section{Test Setup} \label{sec:EVALUATION:1}

We evaluated our implementation with the benchmark suite, the Lively Kernel version, and the machine configuration described in this section.

\subsection{The Octane Benchmark Suite}

% what?
We used the \emph{Octance} benchmark suite\footnote{\url{http://code.google.com/p/octane-benchmark/}, accessed February 3, 2014, at version 26} to evaluate the behavior and performance of our implementation.
Octane consists of eight JavaScript benchmarks.
It is a suite of real programs such as the \emph{DeltaBlue}~\cite{FreemanBenson1990ICS} constraint solver.
It does not test JavaScript's language features systematically.
The benchmarks make, however, use of many important language features, including primitive data types, operators, functions, objects, prototypical inheritance, and many built-in functions.\\
Octane is used in measuring the performance of \emph{v8}, the engine used by Chrome and Node.js.
It is even part of v8's official source code repository\footnote{\url{http://v8.googlecode.com/svn/}, accessed April 23, 2014, at revision 20901}.

% why?
We decided to use Octane for our evaluation for three reasons:

\begin{itemize}
    \item Octane is a standard benchmark suite.
    \item Octane covers many JavaScript language features.
    \item Octane is used in tuning Chrome's JavaScript engine and Chrome is the browser in which the Lively Kernel works best.
\end{itemize}


\subsection{The Lively Kernel}

% what?
During the implementation of our approach, we continuously tested our prototype with the Lively Kernel to make it practically work.

We developed our system in the Lively Kernel repository.
The commit we used for the evaluation is \emph{fc6f3b7e7}\footnote{\url{http://github.com/LivelyKernel/LivelyKernel/commits/fc6f3b7e7}, accessed February 17, 2014}. In this version, most of the Lively Kernel's code is passed through our transformations.
Only the Lively Kernel's bootstrap code, the module system, the extensions to built-in types, and the our implementation are excluded from the source transformations.
All modules loaded after these parts are transformed at load-time.
This includes, for example, all classes of the Lively Kernel.
Transforming these modules enables versioning for the objects created in these modules.

% why?
We tested our implementation with the Lively Kernel for two reasons:

\begin{itemize}
    \item The Lively Kernel is a large JavaScript application that makes use of many features of the JavaScript language and the browser as host environment. The browser provides many additional built-in objects and functions. These built-ins are not part of the ECMAScript standard, but nevertheless used by many browser-based applications. For example, the browser offers many functions to manipulate its document model, which the Lively Kernel uses for rendering.
    \item The goal of this work is provide object versioning for the Lively Kernel. Thus, we are particularly interested in evaluating whether our implementation can be used for recovery support in the Lively Kernel.
\end{itemize}


\subsection{The Test Machine}

% what?
All tests and measurements were done on a Macbook Air with an 2 GHz Intel Core i7 and 8 GB main memory, using Mac OS X 10.9.1, and the most recent stable release of Chrome on February 18, 2014, which was version \emph{32.0.1700.107}.

The presented measurement results were averaged over five runs.

% why?
We used Chrome for all experiments as the Lively Kernel currently works best in Chrome.



\section{Functionality: Versions of the Lively Kernel Runtime} \label{sec:EVALUATION:2}

We tested whether the version-aware references forward correctly to object versions with benchmarks and with the Lively Kernel.

\subsection{Testing with Benchmarks}

We ran the Octane benchmark suite to test the functionality of our implementation.

\paragraph{Method}
% what was done?
We transformed the Octane benchmarks with our source transformations, executed the resulting code, and then checked for JavaScript errors and compared the results of running the transformed benchmarks to their usual results.\\
% why / to test what?
We did this to test two aspects.
First, to test whether our source transformations yield syntactically correct JavaScript code for the benchmarks.
Second, to test whether the our proxy-based version-aware references, inserted by the source transformations, allow to run the benchmarks without errors and with the expected results.


\paragraph{Results}
All benchmarks in this suite run without errors and return the same results as when executed without any source transformations.
That is, at least for these tests, our source transformations produce working source code and our proxy-based version-aware references forward correctly to object versions.\\
During the development of our system, the \emph{DeltaBlue} benchmark revealed a problem when proxies are used as prototypes of objects.
We reported the issue to the \emph{harmony-reflect} repository\footnote{\url{http://github.com/tvcutsem/harmony-reflect/issues/18}, accessed April 23, 2014}.
The problem was identified as an issue with the \emph{v8} JavaScript engine\footnote{\url{http://code.google.com/p/v8/issues/detail?id=2804}, accessed April 23, 2014}.
We virtualized the prototype relation among proxies as workaround for this problem in our implementation, but the issue was subsequentely fixed, rendering the implemented workaround redundant.

\paragraph{Discussion}
The proxies behave like the correct versions of objects in the situations tested by the benchmarks.
While these benchmarks do not test JavaScript's features systematically, they cover a wide range of language features.


\subsection{Testing with the Lively Kernel}

We tested whether the Lively Kernel loads and works with our version-aware references.
Moreover, we tested whether versions of it can be preserved with our implementation.

\paragraph{Method}
% what was done?
We transformed the JavaScript modules of the Lively Kernel at load-time to test whether it loads and works as expected with our versioning system.\\
Furthermore, we tested whether the version-aware references and the linear global undo/redo allow to preserve and re-establish versions of the Lively Kernel's JavaScript runtime in practice.
Here, we tried multiple example scenarios, including to undo changes to the state and behavior of basic morphs, to morph compositions, and to the state of more complicated graphical applications as, for example, text editors and developer tools.\\
% why / to test what?
With this, we tested that the source transformations yield valid JavaScript code for the modules of the Lively Kernel, that the version-aware references delegate correctly to versions of the objects they stand-in for in Lively, and that the version-aware references are used consistently for all mutable objects.


\paragraph{Results}
The Lively Kernel loads when all of its modules are transformed to use version-aware references.
Most of its basic functionality works as expected and we were able to preserve and re-establish runtime states of multiple examples.
However, not all functionality works as expected and we were, thus, also not able to re-establish all preserved states.
This way, we learned about the many built-in functions that currently do not handle ECMAScript 6 Direct Proxies correctly in Chrome.
We implemented the workaround described in Section~\ref{subsec:IMPLEMENTATION:4.3}.

\paragraph{Discussion}
Most of the tested functionality of the the Lively Kernel works as expected.
This includes the entire bootstrap process, rendering graphical objects, loading parts from the Lively Kernel's Parts Bin, and using the Lively Kernel's halo controls.
However, certain functionality of the Lively Kernel is not yet working correctly or even yields errors.
The remaining issues here are expected to be problems related to the built-in functions that do not handle proxies correctly.
Our implementation already unwraps object versions from proxies for many built-in functions, as explained in \ref{subsec:IMPLEMENTATION:4.3}, but the configuration does not cover all problematic built-in functions yet.\\
At the same time, the proxies are not yet fully supported by Chrome and we expect these issues not to be problems once proxies get fully implemented by Chrome.\\



\section{Practicability: Additonal Memory Consumption} \label{sec:EVALUATION:3}

We evaluated the memory overhead of the version-aware references.
Additionally, we measured the memory required for preserving versions.

\subsection{Memory Overhead for Version-aware References}

The version-aware references introduce a constant memory consumption.

\paragraph{Method}
% what was done?
We measured the memory consumption of an empty Lively world when loaded with and without source transformations and, thus, version-aware references.
In this experiment, we did not preserve any versions of the development state.\\
% why / to test what? 
This way, we only measure the overhead of the proxy-based version-aware references themselves as each of those refers to only one version---the original objects, which are present both with version-aware references and without.
We decided to load an empty Lively Kernel world to measure the overhead in a minimal runtime, while expecting the overhead to grow linearly with the number of proxied objects.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/6_evaluation/1_memoryOverhead.pdf}
    \caption{Memory consumption when starting a Lively Kernel world with and without proxies.}
    \label{fig:MemoryOverheadForReferences}
\end{figure}

\paragraph{Results}
As shown in Figure~\ref{fig:MemoryOverheadForReferences}, loading an empty the Lively Kernel world requires three times more space with proxies than without proxies.

\paragraph{Discussion}
Even without preserving multiple versions of any object, the system requires more space when loaded with versioning proxies.
The system uses a proxy for each created mutable object and all references that would usually refer directly to the object refer to the proxy instead.
These proxies require additional space: Each proxy comprises of at least an internal proxy object, a proxy handler object that implements the proxy's behavior, and an ordinary JavaScript object as dictionary for all available versions of the object the proxy stands-in for.
The memory overhead increases linearly with the number of objects accessed through proxies.
While the system creates proxies for most objects, it does not use proxies for all objects.
In particular, it does not create proxies for objects present before our implementation of object versioning is loaded, including all objects used by the versioning implemenation itself.
We expect the number of objects that are excluded from versioning to be relatively stable, while all additional objects created at runtime will be accompanied by proxies.
Currently, the proxies are not optimized to consume as little space as possible.
Two improvements of the current implementation would be to not create a versions dictionary as long as a proxy stands-in for only one version and to have the proxy handlers of all our proxies share their behavior.
The memory overhead, however, does not appear to be problematic at the moment.


\subsection{Memory Usage for Preserving Versions}

Besides the memory required for proxies, memory is required for preserving versions of the runtime.

\paragraph{Method}
% what?
To measure how much memory is required for preserving versions of the runtime state, we measured the memory consumed at three different moments in a simple scenario, which are highlighted as \circnum{1}, \circnum{2}, and \circnum{3} in Figure~\ref{fig:MemoryOverheadForVersions}.
The memory measured is not limited to the memory required for versions, but is instead the memory used by the entire JavaScript runtime.
In particular, we did the following:
\begin{enumerate}
    \item We measured the memory consumed for the state \circnum{1} and then commited the version of the system.
    \item We changed the state to be state \circnum{2}, measured the memory again, and commited that version.
    \item We changed the state to be state \circnum{3} and measured the memory again.
\end{enumerate}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/6_evaluation/2_memoryForVersions.pdf}
    \caption{Memory consumed by the same runtime at three different moments in time, after preserving the previous states.}
    \label{fig:MemoryOverheadForVersions}
\end{figure}

\paragraph{Results}
As shown in Figure~\ref{fig:MemoryOverheadForVersions}, the memory consumption is not very different for the three situations.
The second state required the most memory for the JavaScript runtime, while the memory consumption of the third state is in-between the first and the second.
That is, in this example, the space required for preserving the two states of the morphic objects is insignificant to the space already required for running a Lively Kernel world.

\paragraph{Discussion}
Our implementation does not copy all objects for each version, but only creates copies when objects subsequentely change, effectively storing only the differences between runtime versions.
Therefore, the memory required for preserving versions of the runtime depends on how objects change compared to the predecessor version.
Except for not visible objects created due to mouse interactions, the state \circnum{2} consists of the same objects as state \circnum{1}, but holds multiple versions of the state of the involed morphs and, therefore, the memory footprint increases, but only slightly.
The memory required for the entire JavaScript runtime---not only for preserving versions---does not always increase as there are also temporary objects that are not preserved with any version.
Such temporary objects include the state of JavaScript objects that represent HTML document elements.
These objects can be derived from preserved morph states and, thus, do not have to be preserved.
For this reason, it does not seem odd that state \circnum{3} requires less memory than state \circnum{2}, even though from the third state both previous states can be re-established.\\
\emph{In summary}, the memory overhead for preserving different versions of the runtime does not increase exactly linearly with the number of versions and does not only depend on how many objects are part of the versioned states, but instead highly depends on the differences between preserved versions.



\section{Practicability: Impact on Execution Speed} \label{sec:EVALUATION:4}

We measured the overhead the proxies impose on the execution of benchmarks and the Lively Kernel.
A discussion of the results follows at the end of this section.


\subsection{Measuring Benchmarks}

The Octane benchmark suite shows how the proxies currently slow down a variety of different JavaScript programs.
Two microbenchmarks compare resolving proxy-based version-aware references to following ordinary references.

\subsubsection{Octane Benchmark Suite}

Measuring the Octane benchmark suite highlights how the execution of eight JavaScript programs is affected by the proxies.

\paragraph{Method}
We ran the Octane benchmarks\footnote{Note: We reduced the input size to the Splay benchmark by an order of magnitude to prevent the browser from prompting for user input during the benchmark's execution. The prompt is triggered due to the long time required to run the benchmark. It cannot be disabled and would influence the benchmark result.} with and without previous transformation of the benchmark code and, therefore, with or without version-aware references.
The source transformations for this were done separately and are not reflected in these results.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{figures/6_evaluation/3_executionOverhead.pdf}
    \caption{Execution overhead for proxy-based version-aware references compared to ordinary JavaScript references.}
    \label{fig:ExecutionOverhead}
\end{figure}

\paragraph{Results}
Figure~\ref{fig:ExecutionOverhead} shows how much more time the benchmarks take when their source is transformed before execution and references are, therefore, version-aware.
Executing the benchmarks takes between 90 and 405 times longer with version-aware references than without.
On average the slowdown of a single benchmark is, thus, a 187.5 times.


\subsubsection{Microbenchmarks}

We implemented microbenchmarks to analyze the overhead the proxies impose on references.
In particular, the two microbenchmarks show how much time the proxies require to intercept and forward property reads to object versions.

\paragraph{Method}
In the first setup, we resolved a reference between two objects a million times, where the reference is either an ordinary reference or a proxy-based version-aware reference.
In the second setup, we exchanged the proxy-based version-aware reference with a standard proxy without providing a handler object.
In this case the proxy falls back on the default proxy behavior, which is forwarding to a single target and which we regard as a minimal overhead for reasonable proxy behavior. 

\paragraph{Results}
In the first setup, the microbenchmark takes three orders of magnitude more time when using the version-aware references: instead of on average 10 milliseconds the test requires on average about 11000 milliseconds to finish.
In the second setup, the difference is an order of magnitude less: with a direct reference the benchmark still requires around 10 milliseconds, while the benchmark requires requires close to 2000 milliseconds with a proxy as connection between both objects.
That is, even the default proxy behavior slows down the microbenchmark close to 200 times.



\subsection{Measuring the Lively Kernel}

We measured the overhead of a few typical user interactions and how much longer it takes to load a simple Lively Kernel world.

\subsubsection{Typical Lively Kernel Interactions}

As our goal is to provide recovery support for development in Lively Kernel, the overhead imposed on user interactions is especially interesting as directly affects developers.

\paragraph{Method}
% what?
We measured the overhead for typical user interactions in the Lively Kernel by comparing the time three interactions take when using proxies and when not using proxies, from the time of the user event until the single-threaded JavaScript engine becomes responsive again.
The three typical interaction we chose investigate are: bringing up the halo buttons on a particular morph, opening the world's menu, and opening the Lively Kernel's System Code Browser.\\
% why?
We chose these three interactions as they are expected to be among the more impacted interactions compared to, for example, interactions that are more browser-supported and less reliant on JavaScript execution such as dragging elements around the screen.
All three interaction trigger code from multiple different modules, including event handling code, rendering code, and tool-specific code.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/6_evaluation/4_LivelyInteractionsOverhead.pdf}
    \caption{Execution overhead for three user interactions in the Lively Kernel.}
    \label{fig:LivelyInteractionsOverhead}
\end{figure}

\paragraph{Results}
Figure \ref{fig:LivelyInteractionsOverhead} shows the results, which are comparable for all three interactions.
Each of these interactions takes on average 43 times the time when triggered after the system's was loaded with proxies.



\subsubsection{Loading a World in the Lively Kernel}

Another performance-related question specific to the Lively Kernel is how long it takes to load a world with enabled object versioning.

\paragraph{Method}
We measured how long it takes to load a specific Lively Kernel world both with and without source transformations and, thus, proxies.
Loading a world includes requesting the required modules from the Lively Kernel's server, client-side code to resolve dependencies among modules, evaluating all loaded modules, and deserializing a the Lively Kernel world.
Additionally, in case version-aware references should be used, the sources of all modules also are transformed while loading a world.

\paragraph{Results}
The overhead of loading a world with object versioning is a factor of around eight for loading a world: instead of around 4 seconds, the user would have to wait around 32 seconds until the requested the Lively Kernel world reacts on user interactions.




\subsection{Discussion of the Execution Overhead}

The execution overhead of the current implementation of version-aware references does not appear practical.
The current implementation slows down the JavaScript execution considerably: 

\begin{itemize}
    \item the Octane benchmarks need two to three orders of magnitude more time to finish
    \item the examined user interactions in the Lively Kernel take two orders of magnitude more time
    \item direct comparisons of resolving version-aware references and direct references in a microbenchmark show a slowdown of four orders of magnitude
\end{itemize}

While object versioning could be used to provide the undo/redo of a specific application, it is primalary itented to support development and similar explorative tasks.
That could, conceivably, be an argument for providing object versioning only during development, not when programs are only in-use and should run at full speed.
However, besides having the disadvantage of introducing distinct usage modes, this still requires the version-aware references to resolve fast enough to not impede development significantly, which they currently do not yet do.

We gained the impression that only one order of magnitude is due to the specific proxy behavior, while most of the overhead can be ascribed to using the Direct Proxies as currently available in the Chrome browser.
The proxies are part of an ECMAScript specification that has not yet been finalized and completely implemented by the JavaScript engines.
As explained in Section~\ref{sec:IMPLEMENTATION:1}, the proxies are currently also implemented using a library that relies on an experimental implementation of a previous, deprecated draft of the proxy specification.

Similar behavior forwarding as provided by the proxy handlers could also be implemented in JavaScript, using source transformations and ordinary JavaScript functions.
Instead of using an actual proxy for an object, we could have references point to an ordinary JavaScript object and implement the handler behavior in an ordinary JavaScript function, to be used through further source transformations: instead of \lstinline{obj.prop} the system would execute code similar to \lstinline{get(obj, \"name\")}, where the \lstinline{obj} could still be only a stand-in for many different versions, while \lstinline{get} could implement the behavior previously implemented by respective the proxy trap.
Measuring the performance of such a simple indirection results in a much lower performance overhead for the previously described microbenchmark setup:
it only takes twice the time to read a property from a specific target with a \lstinline{get}-function when compared to reading a property directly.

All this---the experimental status of the proxy implementation, the high cost of proxies even when used with the default handler behavior, and the significantly lower overhead of a custom indirection based on ordinary JavaScript functions---suggest that the performance of the ECMAScript 6 Direct Proxies in Chrome might improve in the future.
At the same time, we might also decide to base our version-aware references on source transformations and custom indirections instead of proxies in the future.
